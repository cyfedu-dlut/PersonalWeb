---
title: "Towards Highly Effective Moving Tiny Ball
Tracking via Vision Transformer"
collection: publications
category: conferences
permalink: /publication/2024-02-18-paper-title-number-5
excerpt: 'Recent tiny ball tracking methods based on deep neural networks have
significantly progressed. However, since moving balls in the video are always
blurred, most existing methods cannot achieve accurate tracking due to limited
receptive fields and sampling depth. Furthermore, as high-resolution competition
videos become increasingly common, existing methods perform poorly on highresolution images. To this end, we provide a strong baseline for tracking tiny
balls called TrackFormer. Firstly, we use Vision Transformer to build the whole
network architecture and enhance the tiny ball localization through its powerful
spatial mining ability. Secondly, we develop a Global Context Sampling Module
(GCSM) to capture more powerful global features, thereby increasing the accuracy of tiny ball identification. Finally, we design a Context Enhancement Module
(CEM) to enhance tiny ball semantics to achieve robust tracking performance. To
promote research and development of tiny ball tracking, we establish a Large-scale
Tiny Ball Tracking dataset called LaTBT. Specifically, LaTBT is founded on three
types of tiny balls (badminton, tennis, and squash), offering more than 300 video
sequences and over 223K annotations from 19 types of professional matches to
address various tracking challenges in diverse and complex backgrounds. To our
knowledge, LaTBT is the first large-scale dataset for tiny ball tracking. Experiments demonstrate that our baseline achieves state-of-the-art performance on our
proposed benchmark dataset. The dataset and the algorithm code are available at
https://github.com/Gi-gigi/TrackFormer.'
date: 2024-08-05
venue: '20th International Conference, ICIC 2024'
paperurl: 'https://cyfedu-dlut.github.io/PersonalWeb/files/trackerformer.pdf'
citation: ''
---
