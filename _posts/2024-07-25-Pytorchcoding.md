---
title: 'PyTorch é«˜é¢‘ä½¿ç”¨ä»£ç '
date: 2024-07-25
permalink: /posts/2024/07/Pytorchcoding/
tags:
  - PyThon
  - PyTorch
  - CUDA
---

PyTorchå¸¸ç”¨ä»£ç æ®µåˆé›†ï¼Œæ¶µç›–åŸºæœ¬é…ç½®ã€å¼ é‡å¤„ç†ã€æ¨¡å‹å®šä¹‰ä¸æ“ä½œã€æ•°æ®å¤„ç†ã€æ¨¡å‹è®­ç»ƒä¸æµ‹è¯•ç­‰5ä¸ªæ–¹é¢ï¼Œè¿˜ç»™å‡ºäº†å¤šä¸ªå€¼å¾—æ³¨æ„çš„Tipsï¼Œå†…å®¹éå¸¸å…¨é¢ã€‚

PyTorchæœ€å¥½çš„èµ„æ–™æ˜¯å®˜æ–¹æ–‡æ¡£ã€‚æœ¬æ–‡æ˜¯PyTorchå¸¸ç”¨ä»£ç æ®µï¼Œåœ¨å‚è€ƒèµ„æ–™(å¼ çš“ï¼šPyTorch Cookbook)çš„åŸºç¡€ä¸Šåšäº†ä¸€äº›ä¿®è¡¥ï¼Œæ–¹ä¾¿ä½¿ç”¨æ—¶æŸ¥é˜…ã€‚

## ğŸ“‘ã€ç›®å½•ã€‘
- [åŸºæœ¬é…ç½®](#1-åŸºæœ¬é…ç½®)
    - [å¯¼å…¥åŒ…å’Œç‰ˆæœ¬æŸ¥è¯¢](#11-å¯¼å…¥åŒ…å’Œç‰ˆæœ¬æŸ¥è¯¢)
    - [å¯å¤ç°æ€§](#12-å¯å¤ç°æ€§)
    - [æ˜¾å¡è®¾ç½®](#13-æ˜¾å¡è®¾ç½®)
    - [æ¸…é™¤æ˜¾å­˜](#14-æ¸…é™¤æ˜¾å­˜)
- [tensorå¼ é‡çš„å¤„ç†](#2-tensorå¼ é‡çš„å¤„ç†)
    - [å¼ é‡çš„æ•°æ®ç±»å‹](#21-å¼ é‡çš„æ•°æ®ç±»å‹)
    - [å¼ é‡åŸºæœ¬ä¿¡æ¯](#22-å¼ é‡åŸºæœ¬ä¿¡æ¯)
    - [å‘½åå¼ é‡](#23-å‘½åå¼ é‡)
    - [æ•°æ®ç±»å‹è½¬æ¢](#24-æ•°æ®ç±»å‹è½¬æ¢)
    - [torchtensorä¸npndarrayè½¬æ¢](#25-torchtensorä¸npndarrayè½¬æ¢)
    - [torchtensorä¸pilimageè½¬æ¢](#26-torchtensorä¸pilimageè½¬æ¢)
    - [npndarrayä¸pilimageçš„è½¬æ¢](#27-npndarrayä¸pilimageçš„è½¬æ¢)
    - [ä»åªåŒ…å«ä¸€ä¸ªå…ƒç´ çš„å¼ é‡ä¸­æå–å€¼](#28-ä»åªåŒ…å«ä¸€ä¸ªå…ƒç´ çš„å¼ é‡ä¸­æå–å€¼)
    - [å¼ é‡å½¢å˜](#29-å¼ é‡å½¢å˜)
    - [æ‰“ä¹±é¡ºåº](#210-æ‰“ä¹±é¡ºåº)
    - [æ°´å¹³ç¿»è½¬](#211-æ°´å¹³ç¿»è½¬)
    - [å¤åˆ¶å¼ é‡](#212-å¤åˆ¶å¼ é‡)
    - [å¼ é‡æ‹¼æ¥](#213-å¼ é‡æ‹¼æ¥)
    - [å°†æ•´æ•°æ ‡ç­¾è½¬ä¸ºone-hotç¼–ç ](#214-å°†æ•´æ•°æ ‡ç­¾è½¬ä¸ºone-hotç¼–ç )
    - [å¾—åˆ°éé›¶å…ƒç´ ](#215-å¾—åˆ°éé›¶å…ƒç´ )
    - [åˆ¤æ–­ä¸¤ä¸ªå¼ é‡ç›¸ç­‰](#216-åˆ¤æ–­ä¸¤ä¸ªå¼ é‡ç›¸ç­‰)
    - [å¼ é‡æ‰©å±•](#217-å¼ é‡æ‰©å±•)
    - [çŸ©é˜µä¹˜æ³•](#218-çŸ©é˜µä¹˜æ³•)
    - [è®¡ç®—ä¸¤ç»„æ•°æ®ä¹‹é—´çš„ä¸¤ä¸¤æ¬§å¼è·ç¦»](#219-è®¡ç®—ä¸¤ç»„æ•°æ®ä¹‹é—´çš„ä¸¤ä¸¤æ¬§å¼è·ç¦»)
    - [å¼ é‡æ±‚å’Œ](#220-å¼ é‡æ±‚å’Œ)

- [æ¨¡å‹å®šä¹‰å’Œæ“ä½œ](#3-æ¨¡å‹å®šä¹‰å’Œæ“ä½œ)
    - [ä¸€ä¸ªç®€å•ä¸¤å±‚å·ç§¯ç½‘ç»œçš„ç¤ºä¾‹](#31-ä¸€ä¸ªç®€å•ä¸¤å±‚å·ç§¯ç½‘ç»œçš„ç¤ºä¾‹)
    - [åŒçº¿æ€§æ± åŒ–æ“ä½œbilinear-pooling](#32-åŒçº¿æ€§æ± åŒ–æ“ä½œbilinear-pooling)
    - [å¤šå¡åŒæ­¥-bnbatch-normalization](#33-å¤šå¡åŒæ­¥-bnbatch-normalization)
    - [å°†å·²æœ‰ç½‘ç»œçš„æ‰€æœ‰bnå±‚æ”¹ä¸ºåŒæ­¥bnå±‚](#34-å°†å·²æœ‰ç½‘ç»œçš„æ‰€æœ‰bnå±‚æ”¹ä¸ºåŒæ­¥bnå±‚)
    - [ç±»ä¼¼-bn-æ»‘åŠ¨å¹³å‡](#35-ç±»ä¼¼-bn-æ»‘åŠ¨å¹³å‡)
    - [è®¡ç®—æ¨¡å‹æ•´ä½“å‚æ•°é‡](#36-è®¡ç®—æ¨¡å‹æ•´ä½“å‚æ•°é‡)
    - [æŸ¥çœ‹ç½‘ç»œä¸­çš„å‚æ•°](#37-æŸ¥çœ‹ç½‘ç»œä¸­çš„å‚æ•°)
    - [æ¨¡å‹å¯è§†åŒ–ä½¿ç”¨pytorchviz](#38-æ¨¡å‹å¯è§†åŒ–ä½¿ç”¨pytorchviz)
    - [ç±»ä¼¼-keras-çš„-modelsummary-è¾“å‡ºæ¨¡å‹ä¿¡æ¯ä½¿ç”¨pytorch-summary](#39-ç±»ä¼¼-keras-çš„-modelsummary-è¾“å‡ºæ¨¡å‹ä¿¡æ¯ä½¿ç”¨pytorch-summary)
- [æ¨¡å‹æƒé‡åˆå§‹åŒ–](#4-æ¨¡å‹æƒé‡åˆå§‹åŒ–)
    - [æå–æ¨¡å‹ä¸­çš„æŸä¸€å±‚](#41-æå–æ¨¡å‹ä¸­çš„æŸä¸€å±‚)
    - [éƒ¨åˆ†å±‚ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹](#42-éƒ¨åˆ†å±‚ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹)
    - [å°†åœ¨-gpu-ä¿å­˜çš„æ¨¡å‹åŠ è½½åˆ°-cpu](#43-å°†åœ¨-gpu-ä¿å­˜çš„æ¨¡å‹åŠ è½½åˆ°-cpu)
    - [å¯¼å…¥å¦ä¸€ä¸ªæ¨¡å‹çš„ç›¸åŒéƒ¨åˆ†åˆ°æ–°çš„æ¨¡å‹](#44-å¯¼å…¥å¦ä¸€ä¸ªæ¨¡å‹çš„ç›¸åŒéƒ¨åˆ†åˆ°æ–°çš„æ¨¡å‹)
- [æ•°æ®å¤„ç†](#5-æ•°æ®å¤„ç†)
    - [è®¡ç®—æ•°æ®é›†çš„å‡å€¼å’Œæ ‡å‡†å·®](#51-è®¡ç®—æ•°æ®é›†çš„å‡å€¼å’Œæ ‡å‡†å·®)
    - [å¾—åˆ°è§†é¢‘æ•°æ®åŸºæœ¬ä¿¡æ¯](#52-å¾—åˆ°è§†é¢‘æ•°æ®åŸºæœ¬ä¿¡æ¯)
    - [tsn-æ¯æ®µsegmenté‡‡æ ·ä¸€å¸§è§†é¢‘](#53-tsn-æ¯æ®µsegmenté‡‡æ ·ä¸€å¸§è§†é¢‘)
    - [å¸¸ç”¨è®­ç»ƒå’ŒéªŒè¯æ•°æ®é¢„å¤„ç†](#54-å¸¸ç”¨è®­ç»ƒå’ŒéªŒè¯æ•°æ®é¢„å¤„ç†)
- [æ¨¡å‹è®­ç»ƒå’Œæµ‹è¯•](#6-æ¨¡å‹è®­ç»ƒå’Œæµ‹è¯•)
    - [åˆ†ç±»æ¨¡å‹è®­ç»ƒä»£ç ](#61-åˆ†ç±»æ¨¡å‹è®­ç»ƒä»£ç )
    - [åˆ†ç±»æ¨¡å‹æµ‹è¯•ä»£ç ](#62-åˆ†ç±»æ¨¡å‹æµ‹è¯•ä»£ç )
    - [è‡ªå®šä¹‰loss](#63-è‡ªå®šä¹‰loss)
    - [æ ‡ç­¾å¹³æ»‘label-smoothing](#64-æ ‡ç­¾å¹³æ»‘label-smoothing)
    - [mixupè®­ç»ƒ](#65-mixupè®­ç»ƒ)
    - [l1-æ­£åˆ™åŒ–](#66-l1-æ­£åˆ™åŒ–)
    - [ä¸å¯¹åç½®é¡¹è¿›è¡Œæƒé‡è¡°å‡weight-decay](#67-ä¸å¯¹åç½®é¡¹è¿›è¡Œæƒé‡è¡°å‡weight-decay)
    - [æ¢¯åº¦è£å‰ªgradient-clipping](#68-æ¢¯åº¦è£å‰ªgradient-clipping)
    - [å¾—åˆ°å½“å‰å­¦ä¹ ç‡](#69-å¾—åˆ°å½“å‰å­¦ä¹ ç‡)
    - [å­¦ä¹ ç‡è¡°å‡](#610-å­¦ä¹ ç‡è¡°å‡)
    - [ä¼˜åŒ–å™¨é“¾å¼æ›´æ–°](#611-ä¼˜åŒ–å™¨é“¾å¼æ›´æ–°)
    - [æ¨¡å‹è®­ç»ƒå¯è§†åŒ–](#612-æ¨¡å‹è®­ç»ƒå¯è§†åŒ–)
    - [ä¿å­˜ä¸åŠ è½½æ–­ç‚¹](#613-ä¿å­˜ä¸åŠ è½½æ–­ç‚¹)
    - [æå–-imagenet-é¢„è®­ç»ƒæ¨¡å‹æŸå±‚çš„å·ç§¯ç‰¹å¾](#614-æå–-imagenet-é¢„è®­ç»ƒæ¨¡å‹æŸå±‚çš„å·ç§¯ç‰¹å¾)
    - [æå–-imagenet-é¢„è®­ç»ƒæ¨¡å‹å¤šå±‚çš„å·ç§¯ç‰¹å¾](#615-æå–-imagenet-é¢„è®­ç»ƒæ¨¡å‹å¤šå±‚çš„å·ç§¯ç‰¹å¾)
    - [å¾®è°ƒå…¨è¿æ¥å±‚](#616-å¾®è°ƒå…¨è¿æ¥å±‚)
    - [ä»¥è¾ƒå¤§å­¦ä¹ ç‡å¾®è°ƒå…¨è¿æ¥å±‚è¾ƒå°å­¦ä¹ ç‡å¾®è°ƒå·ç§¯å±‚](#617-ä»¥è¾ƒå¤§å­¦ä¹ ç‡å¾®è°ƒå…¨è¿æ¥å±‚è¾ƒå°å­¦ä¹ ç‡å¾®è°ƒå·ç§¯å±‚)
- [å…¶ä»–æ³¨æ„](#7-å…¶ä»–æ³¨æ„)
---

### 1. åŸºæœ¬é…ç½®

#### 1.1 å¯¼å…¥åŒ…å’Œç‰ˆæœ¬æŸ¥è¯¢

~~~python
import torch
import torch.nn as nn
import torchvision
print(torch.__version__)
print(torch.version.cuda)
print(torch.backends.cudnn.version())
print(torch.cuda.get_device_name(0))
~~~

#### 1.2 å¯å¤ç°æ€§
åœ¨ç¡¬ä»¶è®¾å¤‡ï¼ˆCPUã€GPUï¼‰ä¸åŒæ—¶ï¼Œå®Œå…¨çš„å¯å¤ç°æ€§æ— æ³•ä¿è¯ï¼Œå³ä½¿éšæœºç§å­ç›¸åŒã€‚ä½†æ˜¯ï¼Œåœ¨åŒä¸€ä¸ªè®¾å¤‡ä¸Šï¼Œåº”è¯¥ä¿è¯å¯å¤ç°æ€§ã€‚å…·ä½“åšæ³•æ˜¯ï¼Œåœ¨ç¨‹åºå¼€å§‹çš„æ—¶å€™å›ºå®štorchçš„éšæœºç§å­ï¼ŒåŒæ—¶ä¹ŸæŠŠnumpyçš„éšæœºç§å­å›ºå®šã€‚
~~~python
np.random.seed(0)
torch.manual_seed(0)
torch.cuda.manual_seed_all(0)

torch.backends.cudnn.deterministic = True
torch.backends.cudnn.benchmark = False
~~~

#### 1.3 æ˜¾å¡è®¾ç½®
å¦‚æœåªéœ€è¦ä¸€å¼ æ˜¾å¡
~~~python
# Device configuration
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
~~~

å¦‚æœéœ€è¦æŒ‡å®šå¤šå¼ æ˜¾å¡ï¼Œæ¯”å¦‚0ï¼Œ1å·æ˜¾å¡ã€‚
~~~python
import os
os.environ['CUDA_VISIBLE_DEVICES'] = '0,1'
~~~

ä¹Ÿå¯ä»¥åœ¨å‘½ä»¤è¡Œè¿è¡Œä»£ç æ—¶è®¾ç½®æ˜¾å¡ï¼š

~~~python
CUDA_VISIBLE_DEVICES=0,1 python train.py
~~~

#### 1.4 æ¸…é™¤æ˜¾å­˜
~~~python
torch.cuda.empty_cache()
~~~
ä¹Ÿå¯ä»¥ä½¿ç”¨åœ¨å‘½ä»¤è¡Œé‡ç½®GPUçš„æŒ‡ä»¤
~~~python
nvidia-smi --gpu-reset -i [gpu_id]
~~~

### 2. Tensorå¼ é‡çš„å¤„ç†

#### 2.1 å¼ é‡çš„æ•°æ®ç±»å‹

PyTorchæœ‰9ç§CPUå¼ é‡ç±»å‹å’Œ9ç§GPUå¼ é‡ç±»å‹ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºï¼š

![åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°](https://i-blog.csdnimg.cn/blog_migrate/b73c6926d29b24007cd928da7f8c0bf1.png#pic_center)


#### 2.2 å¼ é‡åŸºæœ¬ä¿¡æ¯

~~~python
tensor = torch.randn(3,4,5)
print(tensor.type())  
# æ•°æ®ç±»å‹
print(tensor.size())  
# å¼ é‡çš„shapeï¼Œæ˜¯ä¸ªå…ƒç»„
print(tensor.dim())   
# ç»´åº¦çš„æ•°é‡
~~~

#### 2.3 å‘½åå¼ é‡

å¼ é‡å‘½åæ˜¯ä¸€ä¸ªéå¸¸æœ‰ç”¨çš„æ–¹æ³•ï¼Œè¿™æ ·å¯ä»¥æ–¹ä¾¿åœ°ä½¿ç”¨ç»´åº¦çš„åå­—æ¥åšç´¢å¼•æˆ–å…¶ä»–æ“ä½œï¼Œå¤§å¤§æé«˜äº†å¯è¯»æ€§ã€æ˜“ç”¨æ€§ï¼Œé˜²æ­¢å‡ºé”™ã€‚

~~~python
# åœ¨PyTorch 1.3ä¹‹å‰ï¼Œéœ€è¦ä½¿ç”¨æ³¨é‡Š
# Tensor[N, C, H, W]
images = torch.randn(32, 3, 56, 56)
images.sum(dim=1)
images.select(dim=1, index=0)

# PyTorch 1.3ä¹‹å
NCHW = [â€˜Nâ€™, â€˜Câ€™, â€˜Hâ€™, â€˜Wâ€™]
images = torch.randn(32, 3, 56, 56, names=NCHW)
images.sum('C')
images.select('C', index=0)
# ä¹Ÿå¯ä»¥è¿™ä¹ˆè®¾ç½®
tensor = torch.rand(3,4,1,2,names=('C', 'N', 'H', 'W'))
# ä½¿ç”¨align_toå¯ä»¥å¯¹ç»´åº¦æ–¹ä¾¿åœ°æ’åº
tensor = tensor.align_to('N', 'C', 'H', 'W')
~~~

#### 2.4 æ•°æ®ç±»å‹è½¬æ¢
~~~python
# è®¾ç½®é»˜è®¤ç±»å‹ï¼Œpytorchä¸­çš„FloatTensorè¿œè¿œå¿«äºDoubleTensor
torch.set_default_tensor_type(torch.FloatTensor)

# ç±»å‹è½¬æ¢
tensor = tensor.cuda()
tensor = tensor.cpu()
tensor = tensor.float()
tensor = tensor.long()
~~~

#### 2.5 Torch.Tensorä¸Np.Ndarrayè½¬æ¢

é™¤äº†CharTensorï¼Œå…¶ä»–æ‰€æœ‰CPUä¸Šçš„å¼ é‡éƒ½æ”¯æŒè½¬æ¢ä¸ºnumpyæ ¼å¼ç„¶åå†è½¬æ¢å›æ¥ã€‚

~~~python
ndarray = tensor.cpu().numpy()
tensor = torch.from_numpy(ndarray).float()
tensor = torch.from_numpy(ndarray.copy()).float() 
# If ndarray has negative stride.
~~~

#### 2.6 Torch.Tensorä¸PIL.Imageè½¬æ¢

~~~python
# pytorchä¸­çš„å¼ é‡é»˜è®¤é‡‡ç”¨[N, C, H, W]çš„é¡ºåºï¼Œå¹¶ä¸”æ•°æ®èŒƒå›´åœ¨[0,1]ï¼Œéœ€è¦è¿›è¡Œè½¬ç½®å’Œè§„èŒƒåŒ–
# torch.Tensor -> PIL.Image
image = PIL.Image.fromarray(torch.clamp(tensor*255, min=0, max=255).byte().permute(1,2,0).cpu().numpy())
# åŒæ ·çš„è½¬æ¢å½¢å¼ä¸‹é¢å¯ä»¥æ›¿æ¢ï¼Œä¸Šä¸‹ç­‰ä»·
image = torchvision.transforms.functional.to_pil_image(tensor)  

# PIL.Image -> torch.Tensor
path = r'./figure.jpg'
tensor = torch.from_numpy(np.asarray(PIL.Image.open(path))).permute(2,0,1).float() / 255
# Equivalently way
tensor = torchvision.transforms.functional.to_tensor(PIL.Image.open(path))
~~~

#### 2.7 Np.Ndarrayä¸PIL.Imageçš„è½¬æ¢
~~~python
image = PIL.Image.fromarray(ndarray.astype(np.uint8))
ndarray = np.asarray(PIL.Image.open(path))
~~~

#### 2.8 ä»åªåŒ…å«ä¸€ä¸ªå…ƒç´ çš„å¼ é‡ä¸­æå–å€¼
~~~python
value = torch.rand(1).item()
~~~

#### 2.9 å¼ é‡å½¢å˜
~~~python
# åœ¨å°†å·ç§¯å±‚è¾“å…¥å…¨è¿æ¥å±‚çš„æƒ…å†µä¸‹é€šå¸¸éœ€è¦å¯¹å¼ é‡åšå½¢å˜å¤„ç†ï¼Œ
# ç›¸æ¯”torch.viewï¼Œtorch.reshapeå¯ä»¥è‡ªåŠ¨å¤„ç†è¾“å…¥å¼ é‡ä¸è¿ç»­çš„æƒ…å†µ

tensor = torch.rand(2,3,4)
shape = (6, 4)
tensor = torch.reshape(tensor, shape)
~~~

#### 2.10 æ‰“ä¹±é¡ºåº

~~~python
# æ‰“ä¹±ç¬¬ä¸€ä¸ªç»´åº¦
tensor = tensor[torch.randperm(tensor.size(0))]
~~~

#### 2.11 æ°´å¹³ç¿»è½¬

~~~python
# pytorchä¸æ”¯æŒtensor[::-1]è¿™æ ·çš„è´Ÿæ­¥é•¿æ“ä½œï¼Œæ°´å¹³ç¿»è½¬å¯ä»¥é€šè¿‡å¼ é‡ç´¢å¼•å®ç°
# å‡è®¾å¼ é‡çš„ç»´åº¦ä¸º[N, D, H, W].

tensor = tensor[:,:,:,torch.arange(tensor.size(3) - 1, -1, -1).long()]
~~~

#### 2.12 å¤åˆ¶å¼ é‡

~~~python
# Operation                 |  New/Shared memory | Still in computation graph |
tensor.clone()            # |        New         |          Yes               |
tensor.detach()           # |      Shared        |          No                |
tensor.detach.clone()()   # |        New         |          No                |
~~~

#### 2.13 å¼ é‡æ‹¼æ¥

~~~python
'''
æ³¨æ„torch.catå’Œtorch.stackçš„åŒºåˆ«åœ¨äºtorch.catæ²¿ç€ç»™å®šçš„ç»´åº¦æ‹¼æ¥ï¼Œ
è€Œtorch.stackä¼šæ–°å¢ä¸€ç»´ã€‚ä¾‹å¦‚å½“å‚æ•°æ˜¯3ä¸ª10x5çš„å¼ é‡ï¼Œtorch.catçš„ç»“æœæ˜¯30x5çš„å¼ é‡ï¼Œ
è€Œtorch.stackçš„ç»“æœæ˜¯3x10x5çš„å¼ é‡ã€‚
'''
tensor = torch.cat(list_of_tensors, dim=0)
tensor = torch.stack(list_of_tensors, dim=0)
~~~

#### 2.14 å°†æ•´æ•°æ ‡ç­¾è½¬ä¸ºOne-Hotç¼–ç 
é¦–å…ˆæ˜¯ç»å¸¸ä½¿ç”¨çš„torchçš„å½¢å¼ï¼š
pytorchè‡ªå¸¦çš„å°†æ ‡ç­¾è½¬æ¢æˆç‹¬çƒ­ç¼–ç çš„æ–¹æ³•ï¼š
~~~python
torch.nn.funtional.one_hot(tensor,num_classes=-1)->LongTensor
~~~
ä¹Ÿå°±æ˜¯num_classæ§åˆ¶çš„æ˜¯ç‹¬çƒ­ç¼–ç çš„ç»´åº¦ï¼Œé»˜è®¤æŒ‰ç…§å‰é¢tensorå¤§å°è®¾ç½®ï¼Œå‰é¢å¦‚æœæœ€å¤§æ˜¯6ï¼Œåˆ™num_classè®¾ç½®æˆ0-6ä¹Ÿå°±æ˜¯7ï¼›å‰é¢æœ€å¤§2ï¼Œåˆ™num_classä¸º3ã€‚Num_classä¹Ÿå¯ä»¥è®¾ç½®æˆå¤§äºç­‰äºå‰é¢æ•°å­—ä¸­çš„ä»»æ„å€¼ï¼Œé‚£ä¹ˆå°±ç”Ÿæˆå¯¹åº”çš„ç»´åº¦ã€‚
~~~python
# pytorchçš„æ ‡è®°é»˜è®¤ä»0å¼€å§‹
tensor = torch.tensor([0, 2, 1, 3])
N = tensor.size(0)
num_classes = 4
one_hot = torch.zeros(N, num_classes).long()
one_hot.scatter_(dim=1, index=torch.unsqueeze(tensor, dim=1), src=torch.ones(N, num_classes).long())
~~~

#### 2.15 å¾—åˆ°éé›¶å…ƒç´ 

~~~python
# index of non-zero elements
torch.nonzero(tensor) 
# index of zero elements              
torch.nonzero(tensor==0)  
# number of non-zero elements          
torch.nonzero(tensor).size(0)
# number of zero elements       
torch.nonzero(tensor == 0).size(0) 
~~~

#### 2.16 åˆ¤æ–­ä¸¤ä¸ªå¼ é‡ç›¸ç­‰

~~~python
# float tensor
torch.allclose(tensor1, tensor2)  
# int tensor
torch.equal(tensor1, tensor2)     
~~~

#### 2.17 å¼ é‡æ‰©å±•

~~~python
# Expand tensor of shape 64*512 to shape 64*512*7*7.
tensor = torch.rand(64,512)
torch.reshape(tensor, (64, 512, 1, 1)).expand(64, 512, 7, 7)
~~~

#### 2.18 çŸ©é˜µä¹˜æ³•
å•çº¯çš„ä¹˜ç§¯å°±æ˜¯torch.mm
å¿½ç•¥å‰é¢çš„batchç»´åº¦çš„ä¹˜æ³•å°±æ˜¯torch.bmm
é€å…ƒç´ ç›¸ä¹˜çš„ç‚¹ç§¯è¿ç®—åˆ™æ˜¯*ç›´æ¥è¿›è¡Œ

~~~python
# Matrix multiplcation: (m*n) * (n*p) * -> (m*p).
result = torch.mm(tensor1, tensor2)

# Batch matrix multiplication: (b*m*n) * (b*n*p) -> (b*m*p)
result = torch.bmm(tensor1, tensor2)

# Element-wise multiplication.
result = tensor1 * tensor2
~~~

#### 2.19 è®¡ç®—ä¸¤ç»„æ•°æ®ä¹‹é—´çš„ä¸¤ä¸¤æ¬§å¼è·ç¦»

åˆ©ç”¨å¹¿æ’­æœºåˆ¶
~~~python
dist = torch.sqrt(torch.sum((X1[:,None,:] - X2) ** 2, dim=2))
~~~

#### 2.20 å¼ é‡æ±‚å’Œ
ä½¿ç”¨torch.einsum()
ä¸‹é¢ç»™å‡ºä¸€ä¸ªå®ä¾‹ï¼š
~~~python
# trace(è¿¹)
>>> torch.einsum('ii', torch.randn(4, 4))
tensor(-1.4157)

# diagonalï¼ˆå¯¹è§’çº¿ï¼‰
>>> torch.einsum('ii->i', torch.randn(4, 4))
tensor([ 0.0266,  2.4750, -1.0881, -1.3075])

# outer productï¼ˆå¤–ç§¯ï¼‰
>>> x = torch.randn(5)
tensor([-0.3550, -0.6059, -1.3375, -1.5649,  0.2675])
>>> y = torch.randn(4)
tensor([-0.2202, -1.5290, -2.0062,  0.9600])
>>> torch.einsum('i,j->ij', x, y)
tensor([[ 0.0782,  0.5428,  0.7122, -0.3408],
        [ 0.1334,  0.9264,  1.2156, -0.5817],
        [ 0.2945,  2.0451,  2.6834, -1.2840],
        [ 0.3445,  2.3927,  3.1396, -1.5023],
        [-0.0589, -0.4089, -0.5366,  0.2568]])

# batch matrix multiplication(æ‰¹é‡çŸ©é˜µä¹˜æ³•)
>>> As = torch.randn(3,2,5)
tensor([[[-0.0306,  0.8251,  0.0157, -0.4563,  0.5550],
         [-1.4550,  0.0762,  0.9258,  0.1198, -1.1737]],

        [[-0.4460, -0.7224,  0.7260,  0.7552,  0.0326],
         [-0.3904, -1.2392,  0.4848, -0.4756,  0.2301]],

        [[ 1.5307,  0.7668, -1.9426,  1.7473, -0.6258],
         [ 0.6758,  1.8240, -0.2053,  0.0973, -0.6118]]])

>>> Bs = torch.randn(3,5,4)
tensor([[[-0.7054, -0.2155, -1.5458, -0.8236],
         [-1.4957, -2.2604,  0.6897, -1.0360],
         [ 1.2924,  0.2798,  1.0544,  0.3656],
         [-0.3993, -1.2463, -0.6601,  0.2706],
         [ 1.0727,  0.5418, -0.2516, -0.1133]],

        [[ 0.4215,  1.5712, -0.2351,  1.3741],
         [ 1.6418,  0.9806, -1.0259, -1.1297],
         [ 0.7326,  0.4989,  0.4404,  0.2975],
         [-0.6866,  0.5696, -0.8942,  0.6815],
         [ 1.7486,  0.5344,  0.0538,  0.5258]],

        [[ 1.6280, -1.3989, -0.2900,  0.0936],
         [-0.9436, -0.1766,  0.6780,  0.3152],
         [ 0.9645, -0.1199, -1.1644, -1.0290],
         [-0.2791, -0.8086,  0.2161,  0.7901],
         [ 1.3222, -1.4023, -2.4181, -1.2875]]])

>>> torch.einsum('bij,bjk->bik', As, Bs)
tensor([[[-0.4147, -0.9847,  0.7946, -1.0103],
         [ 0.8020, -0.3849,  3.4942,  1.6233]],
        
        [[-1.3035, -0.5993,  0.4922,  0.9511],
         [-1.1150, -1.7346,  2.0142,  0.8047]],
        
        [[-1.4202, -2.5790,  4.2288,  4.5702],
         [-1.6549, -0.4636,  2.7802,  1.7141]]])


# with sublist format and ellipsisï¼ˆå¸¦æœ‰å­åˆ—è¡¨æ ¼å¼å’Œçœç•¥å·ï¼‰
>>> torch.einsum(As, [..., 0, 1], Bs, [..., 1, 2], [..., 0, 2])
tensor([[[-0.4147, -0.9847,  0.7946, -1.0103],
         [ 0.8020, -0.3849,  3.4942,  1.6233]],
        
        [[-1.3035, -0.5993,  0.4922,  0.9511],
         [-1.1150, -1.7346,  2.0142,  0.8047]],
        
        [[-1.4202, -2.5790,  4.2288,  4.5702],
         [-1.6549, -0.4636,  2.7802,  1.7141]]])


# batch permuteï¼ˆæ‰¹é‡äº¤æ¢ï¼‰
>>> A = torch.randn(2, 3, 4, 5)
>>> torch.einsum('...ij->...ji', A).shape
torch.Size([2, 3, 5, 4])


# equivalent to torch.nn.functional.bilinearï¼ˆç­‰ä»·äºtorch.nn.functional.bilinearï¼‰
>>> A = torch.randn(3,5,4)
>>> l = torch.randn(2,5)
>>> r = torch.randn(2,4)
>>> torch.einsum('bn,anm,bm->ba', l, A, r)
tensor([[-0.3430, -5.2405,  0.4494],
        [ 0.3311,  5.5201, -3.0356]])



### 3. æ¨¡å‹å®šä¹‰å’Œæ“ä½œ

#### 3.1 ä¸€ä¸ªç®€å•ä¸¤å±‚å·ç§¯ç½‘ç»œçš„ç¤ºä¾‹

~~~python
# convolutional neural network (2 convolutional layers)
class ConvNet(nn.Module):
    def __init__(self, num_classes=10):
        super(ConvNet, self).__init__()
        self.layer1 = nn.Sequential(
            nn.Conv2d(1, 16, kernel_size=5, stride=1, padding=2),
            nn.BatchNorm2d(16),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2))
        self.layer2 = nn.Sequential(
            nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2),
            nn.BatchNorm2d(32),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2))
        self.fc = nn.Linear(7*7*32, num_classes)

    def forward(self, x):
        out = self.layer1(x)
        out = self.layer2(out)
        out = out.reshape(out.size(0), -1)
        out = self.fc(out)
        return out

model = ConvNet(num_classes).to(device)
~~~

<!-- #### å·ç§¯å±‚çš„è®¡ç®—å’Œå±•ç¤ºå¯ä»¥ç”¨è¿™ä¸ªç½‘ç«™è¾…åŠ©ã€‚ -->

#### 3.2 åŒçº¿æ€§æ± åŒ–æ“ä½œï¼ˆBilinear Poolingï¼‰
bilinear poolingä¸»è¦ç”¨äºç‰¹å¾èåˆ, å¯¹äºä»åŒä¸€ä¸ªæ ·æœ¬æå–å‡ºæ¥çš„ç‰¹å¾ $x$ å’Œç‰¹å¾ $y$, é€šè¿‡bilinear poolingå¾—åˆ°ä¸¤ä¸ªç‰¹å¾èåˆåçš„å‘é‡, è¿› è€Œç”¨æ¥åˆ†ç±»ã€‚
å¦‚æœç‰¹å¾ $x$ å’Œç‰¹å¾ $y$ æ¥è‡ªä¸¤ä¸ªç‰¹å¾æå–å™¨, åˆ™è¢«ç§°ä¸ºå¤šæ¨¡åŒçº¿æ€§æ± åŒ– (MBP, Multimodal Bilinear Pooling)
å¦‚æœç‰¹å¾ $x=$ ç‰¹å¾ $y$, åˆ™è¢«ç§°ä¸ºåŒæºåŒçº¿æ€§æ± åŒ– $\mathrm{Q}$ ï¼ˆHBP, Homogeneous Bilinear Poolingï¼‰æˆ–è€…äºŒé˜¶æ± åŒ–ï¼ˆSecond-order Poolingï¼‰
~~~python
# Assume X has shape N*D*H*W
X = torch.reshape(N, D, H * W)  
# Bilinear pooling                      
X = torch.bmm(X, torch.transpose(X, 1, 2)) / (H * W)  
assert X.size() == (N, D, D)
X = torch.reshape(X, (N, D * D))
# Signed-sqrt normalization
X = torch.sign(X) * torch.sqrt(torch.abs(X) + 1e-5)
# L2 normalization   
X = torch.nn.functional.normalize(X) 
~~~

#### 3.3 å¤šå¡åŒæ­¥ BNï¼ˆBatch Normalizationï¼‰

å½“ä½¿ç”¨ torch.nn.DataParallel å°†ä»£ç è¿è¡Œåœ¨å¤šå¼  GPU å¡ä¸Šæ—¶ï¼ŒPyTorch çš„ BN å±‚é»˜è®¤æ“ä½œæ˜¯å„å¡ä¸Šæ•°æ®ç‹¬ç«‹åœ°è®¡ç®—å‡å€¼å’Œæ ‡å‡†å·®ï¼ŒåŒæ­¥ BN ä½¿ç”¨æ‰€æœ‰å¡ä¸Šçš„æ•°æ®ä¸€èµ·è®¡ç®— BN å±‚çš„å‡å€¼å’Œæ ‡å‡†å·®ï¼Œç¼“è§£äº†å½“æ‰¹é‡å¤§å°ï¼ˆbatch sizeï¼‰æ¯”è¾ƒå°æ—¶å¯¹å‡å€¼å’Œæ ‡å‡†å·®ä¼°è®¡ä¸å‡†çš„æƒ…å†µï¼Œæ˜¯åœ¨ç›®æ ‡æ£€æµ‹ç­‰ä»»åŠ¡ä¸­ä¸€ä¸ªæœ‰æ•ˆçš„æå‡æ€§èƒ½çš„æŠ€å·§ã€‚
~~~python
sync_bn = torch.nn.SyncBatchNorm(num_features, 
                                 eps=1e-05, 
                                 momentum=0.1, 
                                 affine=True, 
                                 track_running_stats=True)
~~~

#### 3.4 å°†å·²æœ‰ç½‘ç»œçš„æ‰€æœ‰BNå±‚æ”¹ä¸ºåŒæ­¥BNå±‚

~~~python
def convertBNtoSyncBN(module, process_group=None):
    '''Recursively replace all BN layers to SyncBN layer.

    Args:
        module[torch.nn.Module]. Network
    '''
    if isinstance(module, torch.nn.modules.batchnorm._BatchNorm):
        sync_bn = torch.nn.SyncBatchNorm(module.num_features, module.eps, module.momentum, 
                                         module.affine, module.track_running_stats, process_group)
        sync_bn.running_mean = module.running_mean
        sync_bn.running_var = module.running_var
        if module.affine:
            sync_bn.weight = module.weight.clone().detach()
            sync_bn.bias = module.bias.clone().detach()
        return sync_bn
    else:
        for name, child_module in module.named_children():
            setattr(module, name) = convert_syncbn_model(child_module, process_group=process_group))
        return module
~~~

#### 3.5 ç±»ä¼¼ BN æ»‘åŠ¨å¹³å‡

å¦‚æœè¦å®ç°ç±»ä¼¼ BN æ»‘åŠ¨å¹³å‡çš„æ“ä½œï¼Œåœ¨ forward å‡½æ•°ä¸­è¦ä½¿ç”¨åŸåœ°ï¼ˆinplaceï¼‰æ“ä½œç»™æ»‘åŠ¨å¹³å‡èµ‹å€¼ã€‚
~~~python
class BN(torch.nn.Module)
    def __init__(self):
        ...
        self.register_buffer('running_mean', torch.zeros(num_features))

    def forward(self, X):
        ...
        self.running_mean += momentum * (current - self.running_mean)
~~~

#### 3.6 è®¡ç®—æ¨¡å‹æ•´ä½“å‚æ•°é‡

~~~python
num_parameters = sum(torch.numel(parameter) for parameter in model.parameters())
~~~

#### 3.7 æŸ¥çœ‹ç½‘ç»œä¸­çš„å‚æ•°

å¯ä»¥é€šè¿‡model.state_dict()æˆ–è€…model.named_parameters()å‡½æ•°æŸ¥çœ‹ç°åœ¨çš„å…¨éƒ¨å¯è®­ç»ƒå‚æ•°ï¼ˆåŒ…æ‹¬é€šè¿‡ç»§æ‰¿å¾—åˆ°çš„çˆ¶ç±»ä¸­çš„å‚æ•°ï¼‰
~~~python
params = list(model.named_parameters())
(name, param) = params[28]
print(name)
print(param.grad)
print('-------------------------------------------------')
(name2, param2) = params[29]
print(name2)
print(param2.grad)
print('----------------------------------------------------')
(name1, param1) = params[30]
print(name1)
print(param1.grad)
~~~

#### 3.8 æ¨¡å‹å¯è§†åŒ–ï¼ˆä½¿ç”¨Pytorchvizï¼‰
~~~
szagoruyko/pytorchvizgithub.com
~~~

#### 3.9 ç±»ä¼¼ Keras çš„ model.summary() è¾“å‡ºæ¨¡å‹ä¿¡æ¯ï¼Œä½¿ç”¨pytorch-summary
~~~
sksq96/pytorch-summarygithub.com
~~~

### 4. æ¨¡å‹æƒé‡åˆå§‹åŒ–

æ³¨æ„ model.modules() å’Œ model.children() çš„åŒºåˆ«ï¼šmodel.modules() ä¼šè¿­ä»£åœ°éå†æ¨¡å‹çš„æ‰€æœ‰å­å±‚ï¼Œè€Œ model.children() åªä¼šéå†æ¨¡å‹ä¸‹çš„ä¸€å±‚ã€‚
~~~python
# Common practise for initialization.
for layer in model.modules():
    if isinstance(layer, torch.nn.Conv2d):
        torch.nn.init.kaiming_normal_(layer.weight, mode='fan_out',
                                      nonlinearity='relu')
        if layer.bias is not None:
            torch.nn.init.constant_(layer.bias, val=0.0)
    elif isinstance(layer, torch.nn.BatchNorm2d):
        torch.nn.init.constant_(layer.weight, val=1.0)
        torch.nn.init.constant_(layer.bias, val=0.0)
    elif isinstance(layer, torch.nn.Linear):
        torch.nn.init.xavier_normal_(layer.weight)
        if layer.bias is not None:
            torch.nn.init.constant_(layer.bias, val=0.0)

# Initialization with given tensor.
layer.weight = torch.nn.Parameter(tensor)
~~~

#### 4.1 æå–æ¨¡å‹ä¸­çš„æŸä¸€å±‚

modules()ä¼šè¿”å›æ¨¡å‹ä¸­æ‰€æœ‰æ¨¡å—çš„è¿­ä»£å™¨ï¼Œå®ƒèƒ½å¤Ÿè®¿é—®åˆ°æœ€å†…å±‚ï¼Œæ¯”å¦‚self.layer1.conv1è¿™ä¸ªæ¨¡å—ï¼Œè¿˜æœ‰ä¸€ä¸ªä¸å®ƒä»¬ç›¸å¯¹åº”çš„æ˜¯name_children()å±æ€§ä»¥åŠnamed_modules(),è¿™ä¸¤ä¸ªä¸ä»…ä¼šè¿”å›æ¨¡å—çš„è¿­ä»£å™¨ï¼Œè¿˜ä¼šè¿”å›ç½‘ç»œå±‚çš„åå­—ã€‚
~~~python
# å–æ¨¡å‹ä¸­çš„å‰ä¸¤å±‚
new_model = nn.Sequential(*list(model.children())[:2] 
# å¦‚æœå¸Œæœ›æå–å‡ºæ¨¡å‹ä¸­çš„æ‰€æœ‰å·ç§¯å±‚ï¼Œå¯ä»¥åƒä¸‹é¢è¿™æ ·æ“ä½œï¼š
for layer in model.named_modules():
    if isinstance(layer[1],nn.Conv2d):
         conv_model.add_module(layer[0],layer[1])
~~~

#### 4.2 éƒ¨åˆ†å±‚ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹

æ³¨æ„å¦‚æœä¿å­˜çš„æ¨¡å‹æ˜¯ torch.nn.DataParallelï¼Œåˆ™å½“å‰çš„æ¨¡å‹ä¹Ÿéœ€è¦æ˜¯

~~~python
model.load_state_dict(torch.load('model.pth'), strict=False)
~~~

#### 4.3 å°†åœ¨ GPU ä¿å­˜çš„æ¨¡å‹åŠ è½½åˆ° CPU
~~~python
model.load_state_dict(torch.load('model.pth', map_location='cpu'))
~~~

#### 4.4 å¯¼å…¥å¦ä¸€ä¸ªæ¨¡å‹çš„ç›¸åŒéƒ¨åˆ†åˆ°æ–°çš„æ¨¡å‹

æ¨¡å‹å¯¼å…¥å‚æ•°æ—¶ï¼Œå¦‚æœä¸¤ä¸ªæ¨¡å‹ç»“æ„ä¸ä¸€è‡´ï¼Œåˆ™ç›´æ¥å¯¼å…¥å‚æ•°ä¼šæŠ¥é”™ã€‚ç”¨ä¸‹é¢æ–¹æ³•å¯ä»¥æŠŠå¦ä¸€ä¸ªæ¨¡å‹çš„ç›¸åŒçš„éƒ¨åˆ†å¯¼å…¥åˆ°æ–°çš„æ¨¡å‹ä¸­ã€‚

~~~python
# model_newä»£è¡¨æ–°çš„æ¨¡å‹
# model_savedä»£è¡¨å…¶ä»–æ¨¡å‹ï¼Œæ¯”å¦‚ç”¨torch.loadå¯¼å…¥çš„å·²ä¿å­˜çš„æ¨¡å‹
model_new_dict = model_new.state_dict()
model_common_dict = {k:v for k, v in model_saved.items() if k in model_new_dict.keys()}
model_new_dict.update(model_common_dict)
model_new.load_state_dict(model_new_dict)
~~~

### 5. æ•°æ®å¤„ç†

#### 5.1 è®¡ç®—æ•°æ®é›†çš„å‡å€¼å’Œæ ‡å‡†å·®
~~~python
import os
import cv2
import numpy as np
from torch.utils.data import Dataset
from PIL import Image

def compute_mean_and_std(dataset):
    # è¾“å…¥PyTorchçš„datasetï¼Œè¾“å‡ºå‡å€¼å’Œæ ‡å‡†å·®
    mean_r = 0
    mean_g = 0
    mean_b = 0

    for img, _ in dataset:
        img = np.asarray(img) # change PIL Image to numpy array
        mean_b += np.mean(img[:, :, 0])
        mean_g += np.mean(img[:, :, 1])
        mean_r += np.mean(img[:, :, 2])

    mean_b /= len(dataset)
    mean_g /= len(dataset)
    mean_r /= len(dataset)

    diff_r = 0
    diff_g = 0
    diff_b = 0

    N = 0

    for img, _ in dataset:
        img = np.asarray(img)

        diff_b += np.sum(np.power(img[:, :, 0] - mean_b, 2))
        diff_g += np.sum(np.power(img[:, :, 1] - mean_g, 2))
        diff_r += np.sum(np.power(img[:, :, 2] - mean_r, 2))

        N += np.prod(img[:, :, 0].shape)

    std_b = np.sqrt(diff_b / N)
    std_g = np.sqrt(diff_g / N)
    std_r = np.sqrt(diff_r / N)

    mean = (mean_b.item() / 255.0, mean_g.item() / 255.0, mean_r.item() / 255.0)
    std = (std_b.item() / 255.0, std_g.item() / 255.0, std_r.item() / 255.0)
    return mean, std
~~~

#### 5.2 å¾—åˆ°è§†é¢‘æ•°æ®åŸºæœ¬ä¿¡æ¯
~~~python
import cv2
video = cv2.VideoCapture(mp4_path)
height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))
width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))
num_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))
fps = int(video.get(cv2.CAP_PROP_FPS))
video.release()
~~~

#### 5.3 TSN æ¯æ®µï¼ˆSegmentï¼‰é‡‡æ ·ä¸€å¸§è§†é¢‘
~~~python
K = self._num_segments
if is_train:
    if num_frames > K:
        # Random index for each segment.
        frame_indices = torch.randint(
            high=num_frames // K, size=(K,), dtype=torch.long)
        frame_indices += num_frames // K * torch.arange(K)
    else:
        frame_indices = torch.randint(
            high=num_frames, size=(K - num_frames,), dtype=torch.long)
        frame_indices = torch.sort(torch.cat((
            torch.arange(num_frames), frame_indices)))[0]
else:
    if num_frames > K:
        # Middle index for each segment.
        frame_indices = num_frames / K // 2
        frame_indices += num_frames // K * torch.arange(K)
    else:
        frame_indices = torch.sort(torch.cat((                              
            torch.arange(num_frames), torch.arange(K - num_frames))))[0]
assert frame_indices.size() == (K,)
return [frame_indices[i] for i in range(K)]
~~~

#### 5.4 å¸¸ç”¨è®­ç»ƒå’ŒéªŒè¯æ•°æ®é¢„å¤„ç†

å…¶ä¸­ ToTensor æ“ä½œä¼šå°† PIL.Image æˆ–å½¢çŠ¶ä¸º HÃ—WÃ—Dï¼Œæ•°å€¼èŒƒå›´ä¸º [0, 255] çš„ np.ndarray è½¬æ¢ä¸ºå½¢çŠ¶ä¸º DÃ—HÃ—Wï¼Œæ•°å€¼èŒƒå›´ä¸º [0.0, 1.0] çš„ torch.Tensorã€‚
~~~python
train_transform = torchvision.transforms.Compose([
    torchvision.transforms.RandomResizedCrop(size=224,
                                             scale=(0.08, 1.0)),
    torchvision.transforms.RandomHorizontalFlip(),
    torchvision.transforms.ToTensor(),
    torchvision.transforms.Normalize(mean=(0.485, 0.456, 0.406),
                                     std=(0.229, 0.224, 0.225)),
 ])
 val_transform = torchvision.transforms.Compose([
    torchvision.transforms.Resize(256),
    torchvision.transforms.CenterCrop(224),
    torchvision.transforms.ToTensor(),
    torchvision.transforms.Normalize(mean=(0.485, 0.456, 0.406),
                                     std=(0.229, 0.224, 0.225)),
])
~~~

### 6ã€‚ æ¨¡å‹è®­ç»ƒå’Œæµ‹è¯•

#### 6.1 åˆ†ç±»æ¨¡å‹è®­ç»ƒä»£ç 

~~~python
# Loss and optimizer
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)

# Train the model
total_step = len(train_loader)
for epoch in range(num_epochs):
    for i ,(images, labels) in enumerate(train_loader):
        images = images.to(device)
        labels = labels.to(device)

        # Forward pass
        outputs = model(images)
        loss = criterion(outputs, labels)

        # Backward and optimizer
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        if (i+1) % 100 == 0:
            print('Epoch: [{}/{}], Step: [{}/{}], Loss: {}'
                  .format(epoch+1, num_epochs, i+1, total_step, loss.item()))
~~~

#### 6.2 åˆ†ç±»æ¨¡å‹æµ‹è¯•ä»£ç 

~~~python
# Test the model
# eval mode(batch norm uses moving mean/variance 
#instead of mini-batch mean/variance)
model.eval()  
              
with torch.no_grad():
    correct = 0
    total = 0
    for images, labels in test_loader:
        images = images.to(device)
        labels = labels.to(device)
        outputs = model(images)
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

    print('Test accuracy of the model on the 10000 test images: {} %'
          .format(100 * correct / total))
~~~

#### 6.3 è‡ªå®šä¹‰Loss
ç»§æ‰¿torch.nn.Moduleç±»å†™è‡ªå·±çš„lossã€‚
~~~python
class MyLoss(torch.nn.Moudle):
    def __init__(self):
        super(MyLoss, self).__init__()

    def forward(self, x, y):
        loss = torch.mean((x - y) ** 2)
        return loss
~~~

#### 6.4 æ ‡ç­¾å¹³æ»‘ï¼ˆLabel Smoothingï¼‰
å†™ä¸€ä¸ªlabel_smoothing.pyçš„æ–‡ä»¶ï¼Œç„¶ååœ¨è®­ç»ƒä»£ç é‡Œå¼•ç”¨ï¼Œç”¨LSRä»£æ›¿äº¤å‰ç†µæŸå¤±å³å¯ã€‚label_smoothing.pyå†…å®¹å¦‚ä¸‹ï¼š
~~~python
import torch
import torch.nn as nn


class LSR(nn.Module):

    def __init__(self, e=0.1, reduction='mean'):
        super().__init__()

        self.log_softmax = nn.LogSoftmax(dim=1)
        self.e = e
        self.reduction = reduction

    def _one_hot(self, labels, classes, value=1):
        """
            Convert labels to one hot vectors

        Args:
            labels: torch tensor in format [label1, label2, label3, ...]
            classes: int, number of classes
            value: label value in one hot vector, default to 1

        Returns:
            return one hot format labels in shape [batchsize, classes]
        """

        one_hot = torch.zeros(labels.size(0), classes)

        #labels and value_added  size must match
        labels = labels.view(labels.size(0), -1)
        value_added = torch.Tensor(labels.size(0), 1).fill_(value)

        value_added = value_added.to(labels.device)
        one_hot = one_hot.to(labels.device)

        one_hot.scatter_add_(1, labels, value_added)

        return one_hot

    def _smooth_label(self, target, length, smooth_factor):
        """convert targets to one-hot format, and smooth
        them.
        Args:
            target: target in form with [label1, label2, label_batchsize]
            length: length of one-hot format(number of classes)
            smooth_factor: smooth factor for label smooth

        Returns:
            smoothed labels in one hot format
        """
        one_hot = self._one_hot(target, length, value=1 - smooth_factor)
        one_hot += smooth_factor / (length - 1)

        return one_hot.to(target.device)

    def forward(self, x, target):

        if x.size(0) != target.size(0):
            raise ValueError('Expected input batchsize ({}) to match target batch_size({})'
                    .format(x.size(0), target.size(0)))

        if x.dim() < 2:
            raise ValueError('Expected input tensor to have least 2 dimensions(got {})'
                    .format(x.size(0)))

        if x.dim() != 2:
            raise ValueError('Only 2 dimension tensor are implemented, (got {})'
                    .format(x.size()))


        smoothed_target = self._smooth_label(target, x.size(1), self.e)
        x = self.log_softmax(x)
        loss = torch.sum(- x * smoothed_target, dim=1)

        if self.reduction == 'none':
            return loss

        elif self.reduction == 'sum':
            return torch.sum(loss)

        elif self.reduction == 'mean':
            return torch.mean(loss)

        else:
            raise ValueError('unrecognized option, expect reduction to be one of none, mean, sum')
~~~

æˆ–è€…ç›´æ¥åœ¨è®­ç»ƒæ–‡ä»¶é‡Œåšlabel smoothing
~~~python
for images, labels in train_loader:
    images, labels = images.cuda(), labels.cuda()
    N = labels.size(0)
    # C is the number of classes.
    smoothed_labels = torch.full(size=(N, C), fill_value=0.1 / (C - 1)).cuda()
    smoothed_labels.scatter_(dim=1, index=torch.unsqueeze(labels, dim=1), value=0.9)

    score = model(images)
    log_prob = torch.nn.functional.log_softmax(score, dim=1)
    loss = -torch.sum(log_prob * smoothed_labels) / N
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()
~~~

#### 6.5 Mixupè®­ç»ƒ
~~~python
beta_distribution = torch.distributions.beta.Beta(alpha, alpha)
for images, labels in train_loader:
    images, labels = images.cuda(), labels.cuda()

    # Mixup images and labels.
    lambda_ = beta_distribution.sample([]).item()
    index = torch.randperm(images.size(0)).cuda()
    mixed_images = lambda_ * images + (1 - lambda_) * images[index, :]
    label_a, label_b = labels, labels[index]

    # Mixup loss.
    scores = model(mixed_images)
    loss = (lambda_ * loss_function(scores, label_a)
            + (1 - lambda_) * loss_function(scores, label_b))
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()
~~~

#### 6.6 L1 æ­£åˆ™åŒ–
~~~python
l1_regularization = torch.nn.L1Loss(reduction='sum')
loss = ...  # Standard cross-entropy loss

for param in model.parameters():
    loss += torch.sum(torch.abs(param))
loss.backward()
~~~

#### 6.7 ä¸å¯¹åç½®é¡¹è¿›è¡Œæƒé‡è¡°å‡ï¼ˆWeight Decay)
pytorché‡Œçš„weight decayç›¸å½“äºl2æ­£åˆ™
~~~python
bias_list = (param for name, param in model.named_parameters() if name[-4:] == 'bias')
others_list = (param for name, param in model.named_parameters() if name[-4:] != 'bias')
parameters = [{'parameters': bias_list, 'weight_decay': 0},                
              {'parameters': others_list}]
optimizer = torch.optim.SGD(parameters, lr=1e-2, momentum=0.9, weight_decay=1e-4)
~~~

#### 6.8 æ¢¯åº¦è£å‰ªï¼ˆGradient Clippingï¼‰
~~~python
torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=20)
~~~

#### 6.9 å¾—åˆ°å½“å‰å­¦ä¹ ç‡
~~~python
# If there is one global learning rate (which is the common case).
lr = next(iter(optimizer.param_groups))['lr']

# If there are multiple learning rates for different layers.
all_lr = []
for param_group in optimizer.param_groups:
    all_lr.append(param_group['lr'])
~~~

å¦ä¸€ç§æ–¹æ³•ï¼Œåœ¨ä¸€ä¸ªbatchè®­ç»ƒä»£ç é‡Œï¼Œå½“å‰çš„lræ˜¯optimizer.param_groups[0]['lr']

#### 6.10 å­¦ä¹ ç‡è¡°å‡
~~~python
# Reduce learning rate when validation accuarcy plateau.
scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=5, verbose=True)
for t in range(0, 80):
    train(...)
    val(...)
    scheduler.step(val_acc)

# Cosine annealing learning rate.
scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=80)
# Reduce learning rate by 10 at given epochs.
scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[50, 70], gamma=0.1)
for t in range(0, 80):
    scheduler.step()    
    train(...)
    val(...)

# Learning rate warmup by 10 epochs.
scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda t: t / 10)
for t in range(0, 10):
    scheduler.step()
    train(...)
    val(...)
~~~

#### 6.11 ä¼˜åŒ–å™¨é“¾å¼æ›´æ–°

ä»1.4ç‰ˆæœ¬å¼€å§‹ï¼Œtorch.optim.lr_scheduler æ”¯æŒé“¾å¼æ›´æ–°ï¼ˆchainingï¼‰ï¼Œå³ç”¨æˆ·å¯ä»¥å®šä¹‰ä¸¤ä¸ª schedulersï¼Œå¹¶äº¤æ›¿åœ¨è®­ç»ƒä¸­ä½¿ç”¨ã€‚
~~~python
import torch
from torch.optim import SGD
from torch.optim.lr_scheduler import ExponentialLR, StepLR
model = [torch.nn.Parameter(torch.randn(2, 2, requires_grad=True))]
optimizer = SGD(model, 0.1)
scheduler1 = ExponentialLR(optimizer, gamma=0.9)
scheduler2 = StepLR(optimizer, step_size=3, gamma=0.1)
for epoch in range(4):
    print(epoch, scheduler2.get_last_lr()[0])
    optimizer.step()
    scheduler1.step()
    scheduler2.step()
~~~

#### 6.12 æ¨¡å‹è®­ç»ƒå¯è§†åŒ–
PyTorchå¯ä»¥ä½¿ç”¨tensorboardæ¥å¯è§†åŒ–è®­ç»ƒè¿‡ç¨‹ã€‚

å®‰è£…å’Œè¿è¡ŒTensorBoardã€‚
~~~python
pip install tensorboard
tensorboard --logdir=runs
~~~

ä½¿ç”¨SummaryWriterç±»æ¥æ”¶é›†å’Œå¯è§†åŒ–ç›¸åº”çš„æ•°æ®ï¼Œæ”¾äº†æ–¹ä¾¿æŸ¥çœ‹ï¼Œå¯ä»¥ä½¿ç”¨ä¸åŒçš„æ–‡ä»¶å¤¹ï¼Œæ¯”å¦‚'Loss/train'å’Œ'Loss/test'ã€‚
~~~python
from torch.utils.tensorboard import SummaryWriter
import numpy as np

writer = SummaryWriter()

for n_iter in range(100):
    writer.add_scalar('Loss/train', np.random.random(), n_iter)
    writer.add_scalar('Loss/test', np.random.random(), n_iter)
    writer.add_scalar('Accuracy/train', np.random.random(), n_iter)
    writer.add_scalar('Accuracy/test', np.random.random(), n_iter)
~~~

#### 6.13 ä¿å­˜ä¸åŠ è½½æ–­ç‚¹
æ³¨æ„ä¸ºäº†èƒ½å¤Ÿæ¢å¤è®­ç»ƒï¼Œæˆ‘ä»¬éœ€è¦åŒæ—¶ä¿å­˜æ¨¡å‹å’Œä¼˜åŒ–å™¨çš„çŠ¶æ€ï¼Œä»¥åŠå½“å‰çš„è®­ç»ƒè½®æ•°ã€‚
~~~python
start_epoch = 0
# Load checkpoint.
if resume: # resumeä¸ºå‚æ•°ï¼Œç¬¬ä¸€æ¬¡è®­ç»ƒæ—¶è®¾ä¸º0ï¼Œä¸­æ–­å†è®­ç»ƒæ—¶è®¾ä¸º1
    model_path = os.path.join('model', 'best_checkpoint.pth.tar')
    assert os.path.isfile(model_path)
    checkpoint = torch.load(model_path)
    best_acc = checkpoint['best_acc']
    start_epoch = checkpoint['epoch']
    model.load_state_dict(checkpoint['model'])
    optimizer.load_state_dict(checkpoint['optimizer'])
    print('Load checkpoint at epoch {}.'.format(start_epoch))
    print('Best accuracy so far {}.'.format(best_acc))

# Train the model
for epoch in range(start_epoch, num_epochs): 
    ... 

    # Test the model
    ...

    # save checkpoint
    is_best = current_acc > best_acc
    best_acc = max(current_acc, best_acc)
    checkpoint = {
        'best_acc': best_acc,
        'epoch': epoch + 1,
        'model': model.state_dict(),
        'optimizer': optimizer.state_dict(),
    }
    model_path = os.path.join('model', 'checkpoint.pth.tar')
    best_model_path = os.path.join('model', 'best_checkpoint.pth.tar')
    torch.save(checkpoint, model_path)
    if is_best:
        shutil.copy(model_path, best_model_path)
~~~

#### 6.14 æå– ImageNet é¢„è®­ç»ƒæ¨¡å‹æŸå±‚çš„å·ç§¯ç‰¹å¾
~~~python
# VGG-16 relu5-3 feature.
model = torchvision.models.vgg16(pretrained=True).features[:-1]
# VGG-16 pool5 feature.
model = torchvision.models.vgg16(pretrained=True).features
# VGG-16 fc7 feature.
model = torchvision.models.vgg16(pretrained=True)
model.classifier = torch.nn.Sequential(*list(model.classifier.children())[:-3])
# ResNet GAP feature.
model = torchvision.models.resnet18(pretrained=True)
model = torch.nn.Sequential(collections.OrderedDict(
    list(model.named_children())[:-1]))

with torch.no_grad():
    model.eval()
    conv_representation = model(image)
~~~

#### 6.15 æå– ImageNet é¢„è®­ç»ƒæ¨¡å‹å¤šå±‚çš„å·ç§¯ç‰¹å¾
~~~python
class FeatureExtractor(torch.nn.Module):
    """Helper class to extract several convolution features from the given
    pre-trained model.

    Attributes:
        _model, torch.nn.Module.
        _layers_to_extract, list<str> or set<str>

    Example:
        >>> model = torchvision.models.resnet152(pretrained=True)
        >>> model = torch.nn.Sequential(collections.OrderedDict(
                list(model.named_children())[:-1]))
        >>> conv_representation = FeatureExtractor(
                pretrained_model=model,
                layers_to_extract={'layer1', 'layer2', 'layer3', 'layer4'})(image)
    """
    def __init__(self, pretrained_model, layers_to_extract):
        torch.nn.Module.__init__(self)
        self._model = pretrained_model
        self._model.eval()
        self._layers_to_extract = set(layers_to_extract)

    def forward(self, x):
        with torch.no_grad():
            conv_representation = []
            for name, layer in self._model.named_children():
                x = layer(x)
                if name in self._layers_to_extract:
                    conv_representation.append(x)
            return conv_representation
~~~

#### 6.16 å¾®è°ƒå…¨è¿æ¥å±‚
~~~python
model = torchvision.models.resnet18(pretrained=True)
for param in model.parameters():
    param.requires_grad = False
model.fc = nn.Linear(512, 100)  # Replace the last fc layer
optimizer = torch.optim.SGD(model.fc.parameters(), lr=1e-2, momentum=0.9, weight_decay=1e-4)
~~~

#### 6.17 ä»¥è¾ƒå¤§å­¦ä¹ ç‡å¾®è°ƒå…¨è¿æ¥å±‚ï¼Œè¾ƒå°å­¦ä¹ ç‡å¾®è°ƒå·ç§¯å±‚
~~~python
model = torchvision.models.resnet18(pretrained=True)
finetuned_parameters = list(map(id, model.fc.parameters()))
conv_parameters = (p for p in model.parameters() if id(p) not in finetuned_parameters)
parameters = [{'params': conv_parameters, 'lr': 1e-3}, 
              {'params': model.fc.parameters()}]
optimizer = torch.optim.SGD(parameters, lr=1e-2, momentum=0.9, weight_decay=1e-4)
~~~

### 7. å…¶ä»–æ³¨æ„
- ä¸è¦ä½¿ç”¨å¤ªå¤§çš„çº¿æ€§å±‚ã€‚å› ä¸ºnn.Linear(m,n)ä½¿ç”¨çš„æ˜¯çš„å†…å­˜ï¼Œçº¿æ€§å±‚å¤ªå¤§å¾ˆå®¹æ˜“è¶…å‡ºç°æœ‰æ˜¾å­˜ã€‚

- ä¸è¦åœ¨å¤ªé•¿çš„åºåˆ—ä¸Šä½¿ç”¨RNNã€‚å› ä¸ºRNNåå‘ä¼ æ’­ä½¿ç”¨çš„æ˜¯BPTTç®—æ³•ï¼Œå…¶éœ€è¦çš„å†…å­˜å’Œè¾“å…¥åºåˆ—çš„é•¿åº¦å‘ˆçº¿æ€§å…³ç³»ã€‚
- model(x) å‰ç”¨ model.train() å’Œ model.eval() åˆ‡æ¢ç½‘ç»œçŠ¶æ€ã€‚

- ä¸éœ€è¦è®¡ç®—æ¢¯åº¦çš„ä»£ç å—ç”¨ with torch.no_grad() åŒ…å«èµ·æ¥ã€‚
model.eval() å’Œ torch.no_grad() çš„åŒºåˆ«åœ¨äºï¼Œmodel.eval() æ˜¯å°†ç½‘ç»œåˆ‡æ¢ä¸ºæµ‹è¯•çŠ¶æ€ï¼Œä¾‹å¦‚ BN å’Œdropoutåœ¨è®­ç»ƒå’Œæµ‹è¯•é˜¶æ®µä½¿ç”¨ä¸åŒçš„è®¡ç®—æ–¹æ³•ã€‚torch.no_grad() æ˜¯å…³é—­ PyTorch å¼ é‡çš„è‡ªåŠ¨æ±‚å¯¼æœºåˆ¶ï¼Œä»¥å‡å°‘å­˜å‚¨ä½¿ç”¨å’ŒåŠ é€Ÿè®¡ç®—ï¼Œå¾—åˆ°çš„ç»“æœæ— æ³•è¿›è¡Œ loss.backward()ã€‚

- model.zero_grad()ä¼šæŠŠæ•´ä¸ªæ¨¡å‹çš„å‚æ•°çš„æ¢¯åº¦éƒ½å½’é›¶, è€Œoptimizer.zero_grad()åªä¼šæŠŠä¼ å…¥å…¶ä¸­çš„å‚æ•°çš„æ¢¯åº¦å½’é›¶.
- torch.nn.CrossEntropyLoss çš„è¾“å…¥ä¸éœ€è¦ç»è¿‡ Softmaxã€‚
- torch.nn.CrossEntropyLoss ç­‰ä»·äº torch.nn.functional.log_softmax + torch.nn.NLLLossã€‚

- loss.backward() å‰ç”¨ optimizer.zero_grad() æ¸…é™¤ç´¯ç§¯æ¢¯åº¦ã€‚

- torch.utils.data.DataLoader ä¸­å°½é‡è®¾ç½® pin_memory=Trueï¼Œå¯¹ç‰¹åˆ«å°çš„æ•°æ®é›†å¦‚ MNIST è®¾ç½® pin_memory=False åè€Œæ›´å¿«ä¸€äº›ã€‚num_workers çš„è®¾ç½®éœ€è¦åœ¨å®éªŒä¸­æ‰¾åˆ°æœ€å¿«çš„å–å€¼ã€‚

- ç”¨ del åŠæ—¶åˆ é™¤ä¸ç”¨çš„ä¸­é—´å˜é‡ï¼ŒèŠ‚çº¦ GPU å­˜å‚¨ã€‚ä½¿ç”¨ inplace æ“ä½œå¯èŠ‚çº¦ GPU å­˜å‚¨ï¼Œå¦‚ï¼š
x = torch.nn.functional.relu(x, inplace=True)
- å‡å°‘ CPU å’Œ GPU ä¹‹é—´çš„æ•°æ®ä¼ è¾“ã€‚ä¾‹å¦‚å¦‚æœä½ æƒ³çŸ¥é“ä¸€ä¸ª epoch ä¸­æ¯ä¸ª mini-batch çš„ loss å’Œå‡†ç¡®ç‡ï¼Œå…ˆå°†å®ƒä»¬ç´¯ç§¯åœ¨ GPU ä¸­ç­‰ä¸€ä¸ª epoch ç»“æŸä¹‹åä¸€èµ·ä¼ è¾“å› CPU ä¼šæ¯”æ¯ä¸ª mini-batch éƒ½è¿›è¡Œä¸€æ¬¡ GPU åˆ° CPU çš„ä¼ è¾“æ›´å¿«ã€‚

- ä½¿ç”¨åŠç²¾åº¦æµ®ç‚¹æ•° half() ä¼šæœ‰ä¸€å®šçš„é€Ÿåº¦æå‡ï¼Œå…·ä½“æ•ˆç‡ä¾èµ–äº GPU å‹å·ã€‚éœ€è¦å°å¿ƒæ•°å€¼ç²¾åº¦è¿‡ä½å¸¦æ¥çš„ç¨³å®šæ€§é—®é¢˜ã€‚

- æ—¶å¸¸ä½¿ç”¨ assert tensor.size() == (N, D, H, W) ä½œä¸ºè°ƒè¯•æ‰‹æ®µï¼Œç¡®ä¿å¼ é‡ç»´åº¦å’Œä½ è®¾æƒ³ä¸­ä¸€è‡´ã€‚

- é™¤äº†æ ‡è®° y å¤–ï¼Œå°½é‡å°‘ä½¿ç”¨ä¸€ç»´å¼ é‡ï¼Œä½¿ç”¨ n*1 çš„äºŒç»´å¼ é‡ä»£æ›¿ï¼Œå¯ä»¥é¿å…ä¸€äº›æ„æƒ³ä¸åˆ°çš„ä¸€ç»´å¼ é‡è®¡ç®—ç»“æœã€‚

- ç»Ÿè®¡ä»£ç å„éƒ¨åˆ†è€—æ—¶ï¼š
~~~python
# æˆ–è€…åœ¨å‘½ä»¤è¡Œè¿è¡Œpython -m torch.utils.bottleneck main.py
with torch.autograd.profiler.profile(enabled=True, use_cuda=False) as profile:    
  ...print(profile)
~~~

- ä½¿ç”¨TorchSnooperæ¥è°ƒè¯•PyTorchä»£ç ï¼Œç¨‹åºåœ¨æ‰§è¡Œçš„æ—¶å€™ï¼Œå°±ä¼šè‡ªåŠ¨ print å‡ºæ¥æ¯ä¸€è¡Œçš„æ‰§è¡Œç»“æœçš„ tensor çš„å½¢çŠ¶ã€æ•°æ®ç±»å‹ã€è®¾å¤‡ã€æ˜¯å¦éœ€è¦æ¢¯åº¦çš„ä¿¡æ¯ã€‚
~~~python
# pip install torchsnooper
import torchsnooper# å¯¹äºå‡½æ•°ï¼Œä½¿ç”¨ä¿®é¥°å™¨@torchsnooper.snoop()

# å¦‚æœä¸æ˜¯å‡½æ•°ï¼Œä½¿ç”¨ with è¯­å¥æ¥æ¿€æ´» TorchSnooperï¼ŒæŠŠè®­ç»ƒçš„é‚£ä¸ªå¾ªç¯è£…è¿› with è¯­å¥ä¸­å»ã€‚
with torchsnooper.snoop():    
  åŸæœ¬çš„ä»£ç 
https://github.com/zasdfgbnm/TorchSnoopergithub.com
~~~

æ¨¡å‹å¯è§£é‡Šæ€§ï¼Œä½¿ç”¨captumåº“ï¼šhttps://captum.ai/captum.ai

# CONTINUE...