---
title: "Talk on group meeting about Segment Anything Model"
collection: talks
type: "Talk"
permalink: /talks/sam
venue: "The internal group meeting"
date: 2024-06-28
location: "Dalian, China"
# image: "https://cyfedu-dlut.github.io/PersonalWeb/images/MAMBA.png"
---

The meeting discussed the Segment Anything model, which is a groundbreaking project characterized by a vast data engine known as SA-1B, containing 100 million masks and 11 million images. This system can be easily constructed and run locally in real-time, with a processing speed of 50 milliseconds per CPU. It supports visual prompt interactions and provides multiple data annotation methods, including manual assistance, semi-automated (similar to LabelStudio), and fully automated approaches. The model's output is divided into three parts: the overall, sub-parts, and sections. Its architecture includes a MASK decoder (similar to MaskFormer), an image encoder (ViT-H), and a prompt encoder (CLIP), supporting prompt tokens and attention mechanisms between images and tokens. You can visit PPT [here](https://cyfedu-dlut.github.io/PersonalWeb/PPT/sam.pdf).

